<html>
<head>
<meta charset="utf-8">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
    },
    TeX: { equationNumbers: { autoNumber: "AMS"} }
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link rel="stylesheet" href="../style.css">
</head>
<body>
<main>
<h1>Maximum Likelihood Estimation</h1>
<div class="grey">
<ol>
<li><a href="#Likelihood">Likelihood</a></li>
<li><a href="#Example 1: Lottery-Ticket">Example 1: Lottery-Ticket</a></li>
<li><a href="#Example 2: Continuous Uniform">Example 2: Continuous Uniform</a></li>
</ol>
</div>
<h3 id="Likelihood">Likelihood</h3>
A <b>likelihood function</b> tells you how probably ("likely") you were to get the data, given some set of parameter values. For instance, imagine I have a bag with balls numbered from 1 to some unknown integer, $b$. If I draw a 4, I can calcluate the likelihood of this for different possible $n$s:

<table>
<tr><td>$b$</td><td>Likelihood</td></tr>
<tr><td>1</td><td>0.0000</td></tr>
<tr><td>2</td><td>0.0000</td></tr>
<tr><td>3</td><td>0.0000</td></tr>
<tr><td>4</td><td>0.2500</td></tr>
<tr><td>5</td><td>0.2000</td></tr>
<tr><td>6</td><td>0.1667</td></tr>
<tr><td>n</td><td>$\frac{1}{n}$</td></tr>
</table>

For example $b=2$, then it is impossible for me to draw a 4. If $b=10$, then there is exactly a 1-in-10 chance of drawing a 4, so the likelihood is $\frac{1}{10}$. A <b>likelihood funciton</b> is a function that takes a parameter value(s) and returns the likelihood of the observed data. In this case, the likelihood function is

$$L\left(n\right) = \left\{
     \begin{array}{lr}
       0 & : n \lt 4\\
       \frac{1}{n} & : n \geq 4\\
     \end{array}
   \right.\\$$

<br><br>
In general, the likelihood function is defined as

$$L(\theta) = P(X_1,X_2,...,X_n | \theta)$$

where the $X$s are observed data values and $\theta$ is some parameter.
<br><br>
Maximium likelihood estimation is based on the idea that, the most intuitive way to estimate a parameter's value is to choose the value that was most likely to produce the observed data. In this case, we'd say that the best estimate for $n$ is 4. Maximum likelihood estimation has the advantage that the answers it gives are always possible and reasonable.
<h3 id="Example 1: Lottery-Ticket">Example 1: Lottery-Ticket</h3>
Using our lottery-ticket example, we expect a uniform distribution from 1 to $b$, and we want an estimate for the value of $b$. First, we have to calculate the likelihood function:
$$L(b) = P(X_1,X_2,...,X_n | b)$$
Because we sampled each ticket is randomly, they are independent events, so we can break this apart into
$$L(b) = P(X_1 | b) \cdot P(X_2 | b) \cdots P(X_n | b)$$

If any $X_i$ is larger than some $b$, then we know that this value for $b$ is impossible. To give a more concrete example, if $X_7$ is 15, then we know that $b$ must be at least 15. If, on the other hand, $b$ is larger than every $X$, then

$$L(b) = P(X_1 | b) \cdot P(X_2 | b) \cdots P(X_n | b) = \frac{1}{b} \cdot \frac{1}{b} \cdots \frac{1}{b} = \frac{1}{b^n}$$

Therefore,

$$L\left(b \right) = \left\{
     \begin{array}{lr}
       0 & : b \lt max\left(\{X_1,...,X_n\}\right) \\
       \frac{1}{b^n} & : b \geq max\left(\{X_1,...,X_n\}\right) \\
     \end{array}
   \right.\\$$

Graphing this out looks like:

<img src="uniform likelihood.png" style="max-width:300px;">

It should be clear that $L(b)$ is maximized when $b$ is equal to the value of the maximum datapoint. For the lottery-ticket data, we have a maximum of 217, so the maximum likelihood estimate for $b$ is 217.
<h3 id="Example 2: Continuous Uniform">Example 2: Continuous Uniform</h3>
Let's say we have a continuous uniform distribution from 0 to $b$. We <a href="Sampling Distributions.html#Example: Maximum of the Uniform">know</a> that the sampling distribution follows

$$f(m)=\frac{nm^{n-1}}{b^n}, m \leq b$$

For some given $b$, this sampling distribution gives the probability of obtaining some maximum, $m$. If we just think of this as a function of $b$ though, this becomes a likelihood. In other words

$$f(m,b)=\frac{nm^{n-1}}{b^n}, m \leq b$$

tells us the probability of getting a sample maximum of $m$ given some distribution maximum, $b$.
<br><br>
Now, we just have to find the $b$ that maximizes $f(m,b)$ for some $m$ that we can compute from our data. This becomes a simple calculus problem of find a maximum. At this point, we'll leave this as an exercise for the reader, but, essentially, the derivative $\frac{df}{db}$ is always negative, so we should choose the smallest possible value for $b$ - thus, the likelihood is maximized at $b=m$.
</main>
</body>
</html>